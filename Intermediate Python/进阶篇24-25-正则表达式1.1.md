# 老王Python学习笔记
> 运行环境：代码编辑器sublime text 3（配置anaconda，python3.5）
## 二、进阶篇

### 进阶篇24-25-正则表达式
> 注意：py文件名不要与与已有模块或库重名，否则会抛出意想不到的异常。

正则表达式，是字符串检索引擎，最早起源于unix。

1. unix下的正则 awk grep egrep
2. wins下的正则
2. 正则的几个基本概念

[0-9] \d 全部数字 

\w 单词类字符 a-z A-Z 0-9 _

\W 非单词类字符

{2}  {n}  前面的表达式匹配n次

{0,2} {m,n} 前面的表达式匹配m到n次

+表示前面的表达式，出现1到无限次  即最少出现1次

?表示前面的表达式，出现0到1次  即最多出现1次

*表示前面的表达式，出现0到无限次 即出现任意次数

---
### 下节课内容
3. python里的正则模块 re

4. 一些基本操作
5. 
4.1 一次取配 match:"hello lilei"  r'(\w+) (\w+)'
```
a = '123456abc'
b = 'abc123456'
c = '123456abc'
# 格式匹配
print(re.match(r'\d', a)) # 从开始匹配数字
print(re.match(r'\d', b)) # 从开始匹配数字
print(re.match(r'\w+', c)) # 从开始匹配数字字母
>>>
<_sre.SRE_Match object; span=(0, 1), match='1'>
None
<_sre.SRE_Match object; span=(0, 9), match='123456abc'>


# 取出内容
d = 'winter is coming'
m = re.match(r'(\w+) (\w+) (\w+)', d)
print(m.groups()) # 分组取出全部内容
print(m.group(1)) # 取出分组1的内容
>>>
('winter', 'is', 'coming')
winter
```
4.2 切割 split
```
# 字符串分割
url = 'http://www.baidu.com'
e = 'q1w2e3r4t'
s = re.split(r'\W', url)  # 以非数字字母作为分隔符
f = re.split(r'\d', e)  # 以数字作为分隔符
print(s)
print(f)
>>>
['http', '', '', 'www', 'baidu', 'com']
['q', 'w', 'e', 'r', 't']
```

4.3 查找全部 findall
```
# findall查找全部
e = 'q1w2e3r4t'
url = 'http://www.baidu.com'
f = re.findall(r'\d', e)  # 查找全部数字
s = re.findall(r'\W', url)  # 查找全部非数字字母
print(f)
print(s)
>>>
['1', '2', '3', '4']
[':', '/', '/', '.', '.']
```
4.4 finditer 迭代器什么的最有爱了

```
# coding=utf-8
import re

text = 'Guido will be out of offcie from 12/15/2012 - 1/3/2013'
# 日期的正则表达式模式
datepat = re.compile('(\d+)/(\d+)/(\d+)')

# 找到并打印所有的日期
for m in datepat.finditer(text):
    print(m)

# 找到所有日期并以一种不同的方式打印
monthname = ['None', 'Jan', 'Feb', 'Mar', 'Apr', 'May',
             'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
for m in datepat.finditer(text):
    print('%s %s, %s' % (monthname[int(m.group(1))], m.group(2), m.group(3)))


# 将所有日期替换成欧洲日期格式（日/月/年）
def fix_date(m):
    return '%s/%s/%s' % (m.group(2), m.group(1), m.group(3))


newtext = datepat.sub(fix_date, text)
print(newtext)

# 一种可选的替换方式
newtext = datepat.sub(r'\3/\1/\2', text)
print(newtext)
```

---

### 习题：

1 已知字符串:
info = '<a href="http://www.baidu.com">baidu</a>'

用正则模块提取出网址："http://www.baidu.com"和链接文本:"baidu"

```
# coding=utf-8
import re

'''
1 已知字符串:
info = '<a href="http://www.baidu.com">baidu</a>'
用正则模块提取出网址："http://www.baidu.com"和链接文本:"baidu"
'''
info = '<a href="http://www.baidu.com">baidu</a>'
url = re.findall(r"http+.+com", info)
text = re.findall('\w+(?=</a>)', info)
print(url)
print(text)
>>>
['http://www.baidu.com']
['baidu']
```
---
2 字符串："one1two2three3four4" 用正则处理，输出 "1234"

```
# coding=utf-8
import re
a = "one1two2three3four4"
num = re.split('[a-z]+', a)        # 使用字母分割字符串
new_list = [x for x in num if x]   # 去除空值
new_str = ''.join(new_list)        # 聚合所有数字
print(new_str)
>>>1234
```
---
3 已知字符串：text = "JGood is a handsome boy, he is cool, clever, and so on..." 查找所有包含'oo'的单词。

```
# coding=utf-8
import re

'''
3 已知字符串：text = "JGood is a handsome boy, he is cool, clever, and so on..."
查找所有包含'oo'的单词。
'''
# method 01
text = "JGood is a handsome boy, he is cool, clever, and so on..."
word = re.findall('\w+oo\w+', text)
print(word)
>>> ['JGood', 'cool']
# method 02
text = "JGood is a handsome boy, he is cool, clever, and so on..."
word = re.split('\W+', text)
oow = [x for x in word if 'oo' in x]
print(oow)
>>> ['JGood', 'cool']
```
---
4 为什么在unix里，grep后面的正则有些时候要加引号，有些时候不需要。


1. 要查找的内容含空格等，就非要引号不可啦。
2. [grep正则表达式后面的单引号和双引号的区别？](http://blog.csdn.net/liaoshengshi/article/details/47905163)

---
5 已知字符串：

info = 'test,&nbsp;url("http://www.baidu.com")&,dddddd "="" <svg></svg><path></path><img src="http://www.baidu.com">ininnnin<img src="http://www.dd.com">'

要求完成下面2个小功能：

1.1 关闭[img]标签

1.2 将url()中的["]转为[']

最后结果字符串：

"test,&nbsp;url('http://www.baidu.com')&,dddddd "="" <svg></svg><path></path><img src="http://www.baidu.com"></img>ininnnin<img src="http://www.dd.com"></img>"

```
# coding=utf-8
'''
1.1 关闭[img]标签
1.2 将url()中的["]转为[']
@问题：搞不定？？？
'''
info = 'test, url("http://www.baidu.com")&,dddddd "="" <svg></svg><path></path><img src="http://www.baidu.com">ininnnin<img src="http://www.dd.com">'

import re

s1 = re.sub(r'\"', r'\'', info, count=2) # 单引号替换为双引号
s = re.sub(r"<img.*>", r"></img>", s1)  # 关闭[img]标签，没有实现该功能
print(s)
>>>
test, url(\'http://www.baidu.com\')&,dddddd "="" <svg></svg><path></path>></img>
```
# 老王Python学习笔记
> 运行环境：代码编辑器sublime text 3（配置anaconda）
## 二、进阶篇

### 进阶篇9、10-函数周末习题

1. 处理文件夹相关问题可考虑使用递归
2. open()文件读写模式：
- w     以写方式打开，
- a     以追加模式打开 (从 EOF 开始, 必要时创建新文件)
- r+     以读写模式打开
- w+     以读写模式打开
- a+     以读写模式打开
- rb     以二进制读模式打开
- wb     以二进制写模式打开
- ab     以二进制追加模式打开
- rb+    以二进制读写模式打开
- wb+    以二进制读写模式打开 
- ab+    以二进制读写模式打开



---

#### 习题

1. 定义一个func(url, folder_path)，获取url地址的内容，保存在folder_path文件目录下，并随机生成文件名
2. 定义一个func(folder_path)，合并该目录下的所有文件，并生成文件all.txt
3. 定义一个func(url)，分析该url内容里有多少个链接
4. 定义一个func(url)，获取他？后的参数，并返回一个dict

   assert func("http://url/api?param=2&param2=4") == {'param': '2', 'param2': '4'}
5. 定义一个func(folder)，删除文件目录下的所有文件

---

#### 习题答案
>参考资料：[Python3中内置类型bytes和str用法及byte和string之间各种编码转换](http://www.cnblogs.com/zanjiahaoge666/p/6402907.html)

```
import urllib.request
import random
import os


def save_url_content(url, folder_path=None):
    """
    1.定义一个func(url, folder_path)，获取url地址的内容，保存在folder_path文件目录下，并随机生成文件名
    @问题：write()函数写入网页内容, 由于只能写入字符串，无法写入字节，因此decode bytes -> str，结果报错。
    """

    # 判断url是否是合法的网页地址
    if not (url.startswith('http://') or url.startswith('https://')):
        return u'url地址不符合规格'

    if not os.path.isdir(folder_path):  # 判断文件路径是否合法
        return u'folder_path非文件夹'

    d = urllib.request.urlopen(url)  # 打开网页
    content = d.read()               # 读取网页内容(encode str -> bytes)
    rand_filename = 'test_%s' % random.randint(1, 1000)   # 随机生成文件名，str类型
    file_path = os.path.join(folder_path, rand_filename)  # 聚合多个文件路径
    d = open(file_path, 'ab+')   # 生成一个空白文本
    d.write(content)  # 写入网页内容, 'ab+'是以二进制读写模式打开文件
    d.close()
    return file_path

print(save_url_content('http://library.cup.edu.cn/',/
r'C:\Program Files\Sublime Text 3\practice'))
>>> C:\Program Files\Sublime Text 3\practice\test_167

```
    
---

```
import os
# 使用递归去解决
def merge(folder_path):
    "2. 定义一个func(folder_path)，合并该目录下的所有文件，并生成文件all.txt"
    if not os.path.exists(folder_path):
        return 'folder_path not exists'

    for f in os.listdir(folder_path):
        file_path = os.path.join(folder_path, f)
        if os.path.isdir(file_path):
            merge(file_path)
        else:
            merge_file = open('all.txt', 'ab+')     # 新建空白文本all.txt
            content = open(file_path, 'rb').read()  # 以二进制读'rb'模式读取文件路径下的文件内容
            merge_file.write(content)               # 向all.txt写入读取的文件内容
            merge_file.close()


merge(r'C:\Program Files\Sublime Text 3\practice')


```
---
    
```
import urllib.request

def get_url_count(url):
    "3.定义一个func(url)，分析该url内容里有多少个链接"
    if not (url.startswith('http://') or url.startswith('https://')):
        return u'url地址不符合规格'
    d = urllib.request.urlopen(url)
    content = d.read()
    content_list = content.split(b'<a href=')
    return len(content_list) - 1
    '''
    1. 网页源代码中以'<a href='开头的对象表示可以访问的链接，所以'<a href='的数量即为链接数量
    2. 字符串方法split可以将网页内容以'<a href='分割成list，分隔符'<a href='的数量等于len(list)-1
    '''
```

---

```
import urllib.parse


def qs(url):
    "4. 定义一个func(url)，获取他？后的参数，并返回一个dict"
    query_str = urllib.parse.urlparse(url).query   # 获取？后的参数，str类型

    # 字典query中的值是list，如{'g': ['6'], 'y': ['5'], 'f': ['5']}
    query_dict = urllib.parse.parse_qs(query_str)

    # 将字典的list类型的值转化为str
    return dict([(k, v[0]) for k, v in query_dict.items()])


print(qs('http://126.com'))
>>> {}

print(qs('http://api/api?f=5&g=6&y=5'))
>>> {'g': '6', 'y': '5', 'f': '5'}

print(qs('http://api/api?11=53'))
>>> {'11': '53'}

```

---

```
import os

def delete(folder_path):
    "5. 定义一个func(folder)，删除文件目录下的所有文件"
    if not os.path.exists(folder_path):
        return 'folder_path not exists'

    for f in os.listdir(folder_path):
        file_path = os.path.join(folder_path, f)
        if os.path.isdir(file_path):
            delete(file_path)
        else:
            os.remove(file_path)

```